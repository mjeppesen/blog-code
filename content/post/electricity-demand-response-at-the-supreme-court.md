---
title: "Electricity Demand Response At The Supreme Court"
date: 2017-10-30T20:40:44+11:00
---

How much should people be paid _not_ to use electricity? A dispute on the fundamental economics of this went to the US Supreme court recently.

{{<figure src="/images/supreme_court.svg" >}}

In the electricity industry, where I work, it is important to keep supply (the energy being provided by the generators) balanced with demand (the energy being used by customers) _at all times_. If this is not done, the entire system will quickly collapse and fail to what is called "system black". It is very different to the situation in most industries. Consider, for example, if Apple does not make enough new iPhones to satisfy demand. All the iPhones that are made will be bought by someone, and everyone else who wants to buy one will either have to wait until more phones are made, or buy another kind of phone. If the phone market were similar to the electricity market, an analogous situation would be that if even one person went to the store and could not purchase a new iPhone, then all other iPhones stopped working.

For electricity grid operators, this fact makes it hard to run the power system securely when electricity demand is very high (typically on hot days). There is nothing to stop people from connecting additional appliances to the grid. Even though wholesale prices rise very high at these times (over 300 times the average price), most people are either unaware of such prices or any not exposed to them (i.e. the price paid by their retailer rises but the customers themselves have a fixed price). For many kinds of loads, the demand rises automatically without any person even being involved. For example, many air conditioners have a set temperature to which they try to cool a building down to. If the outside temperature increases, the air conditioners automatically start working harder (therefore using more electricity) in response.

One way that this problem is managed is called _demand response_, which is essentially paying customers to use less electricity at certain times than they normally would. This is often done in indirect ways, as suits different customers and their habits. One example will be trialled by the retailer Powershop this summer, supported by The Australian Energy Market Operator (AEMO) and Australian Renewable Energy Agency (ARENA). Powershop will use a smart phone app to tell people to reduce their demand at certain times, with the reward being a week or so of free electricity.

Which brings us to the question: if you are going to pay someone to use less power than they normally would, what is the right amount to pay them? If a person normally pays $50/MWh for their electricity use, and prices rise to $500/MWh: should they be paid:

 - $500/MWh for each MWh of reduced demand (the current price), or
 - $450/MWh (the current price minus the price usually paid)?

This was argued in a 2016 Supreme court case, where the two sides disagreed on the _fundamental economic theory_ of the question.

FERC (the US regulator) had created a demand response program that required energy markets to pay the current price ($500/MWh in the above example). The EPSA (a generator industry group), which was opposed to the demand response scheme, argued that FERC did not have the authority to create a demand response scheme, or that if it the compensation should be the current price _minus_ the normal price for the customer ($450/MWh in the above example). Harvard economics professor Bill Hogan contributed a "friend of the court" brief in support of the EPSA, arguing that FERC was forcing grid operators to overpay for demand response by, in the example above, forcing them to pay $500/MWh.

Here is an extract from Hogan's brief:

_"To offer an analogy, consider a manufacturer that produces an automobile it can sell to a dealer for $20,000; the dealer has agreed to then sell the automobile to a customer at cost ($20,000), but cars are in high demand and another customer wants to buy the car for $30,000. No one would say that the first customer should be paid $30,000 for not buying the car, just because another customer wants it or cars are in short supply. If one customer has a right to buy the car at $20,000, while another is willing to pay $30,000--and lack of supply means that both cannot purchase cars--the dealer could, in theory, sell the car to the second customer and give the first customer the $10,000 difference between the market price and the price at which she has the right to purchase. That would allocate the car to the customer who values it more, while giving the first customer an incentive to allow the second customer to have it. We would never, however, say that the dealer must: (1) pay the manufacturer $30,000; (2) pay the first customer $30,000 (the car's current value) for not buying the car; and (3) sell the car at $30,000 (again its current value) for a loss. But that is what FERC effectively has done: It provides the first customer with a windfall while requiring [grid operators] to pay twice (to the electricity producer and the non-buyer) for a unit of electricity that they may only sell once for less than the total price paid."_

However, in an earlier affidavit, Professor Kahn of Cornell University argued (and FERC agreed), that reducing demand was equivalent to increasing generation, and should receive the same compensation, meaning that the $500/MWh would be the correct price above. From Kahn's affidavit:

_demand response is in all essential respects economically equivalent to supply response; and that economic efficiency requires, that it should be rewarded with the same [price] that clears the market. Since DR is actually--and not merely metaphorically--equivalent to supply response, economic efficiency requires that it be regarded and rewarded, equivalently, as a resource proffered to system operators, and be treated equivalently to generation in competitive
power markets_

What do you think? It is a subtle difference. In the above example, the $450/MWh case is equivalent to the customer buying electricity at their regular price of $50/MWh, and immediately selling it to the market at the market price of $500/MWh, for a profit of $450/MWh, instead of using the electricity themselves.

In the end the Supreme court, by a 6--2 verdict, sided with FERC and against the EPSA, but did not endorse any particular method for determining the price. The Court judged that FERC _did_ have the authority to create a demand response scheme, and that both sides made valid points on the price, but since FERC has the authority to choose the price, so FERC's price should be used.

What do I think? I admit that I am not an expert in these matters -- nothing like the experts quoted above -- but for what is worth, I believe that Hogan's argument is correct, and that $450/MWh would be the correct price. From my perspective, demand response by a customer is equivalent to selling their right to use electricity to someone else. To do that, they need to have the right to use electricity, and if they have to pay $50/MWh to obtain that right (and hence receive $450/MWh overall), then that is what they need to do.


References

In another amiCharles Kolstad, an economist at Stanford University, wrote a brief to support FERC. Kolstad thought that the Hogan price method was economically optimal, but that the FERC method was still fine, and because demand response schemes were a good idea,

The Supreme court decided that FERC had the power to create a demand response scheme, but ruled that it could continue with its previous compensation scheme.


However, the Supreme Court disagreed. Here is an extract from the majority opinion, by Justice Kagan:




Alfred E. Kahn, Affidavit attached to “Reply Comments of the Demand Response Supporters,”
Docket No. RM10-17-000, August 30, 2010, p. 2


http://sblog.s3.amazonaws.com/wp-content/uploads/2015/07/Kolstad-Br..pdf
